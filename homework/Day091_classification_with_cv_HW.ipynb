{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業目標\n",
    "* 嘗試比較用 color histogram 和 HOG 特徵來訓練的 SVM 分類器在 cifar10 training 和 testing data 上準確度的差別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" # 使用 CPU\n",
    "\n",
    "import numpy as np\n",
    "import cv2 # 載入 cv2 套件\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train, test = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 產生直方圖特徵的訓練資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_histogram = []\n",
    "x_test_histogram = []\n",
    "\n",
    "# 對於所有訓練資料\n",
    "for i in range(len(x_train)):\n",
    "    chans = cv2.split(x_train[i]) # 把圖像的 3 個 channel 切分出來\n",
    "    # 對於所有 channel\n",
    "    hist_feature = []\n",
    "    for chan in chans:\n",
    "        # 計算該 channel 的直方圖\n",
    "        hist = cv2.calcHist([chan], [0], None, [16], [0, 256]) # 切成 16 個 bin\n",
    "        hist_feature.extend(hist.flatten())\n",
    "    # 把計算的直方圖特徵收集起來\n",
    "    x_train_histogram.append(hist_feature)\n",
    "\n",
    "# 對於所有測試資料也做一樣的處理\n",
    "for i in range(len(x_test)):\n",
    "    chans = cv2.split(x_test[i]) # 把圖像的 3 個 channel 切分出來\n",
    "    # 對於所有 channel\n",
    "    hist_feature = []\n",
    "    for chan in chans:\n",
    "        # 計算該 channel 的直方圖\n",
    "        hist = cv2.calcHist([chan], [0], None, [16], [0, 256]) # 切成 16 個 bin\n",
    "        hist_feature.extend(hist.flatten())\n",
    "    x_test_histogram.append(hist_feature)\n",
    "\n",
    "x_train_histogram = np.array(x_train_histogram)\n",
    "x_test_histogram = np.array(x_test_histogram)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 產生 HOG 特徵的訓練資料\n",
    "* HOG 特徵通過計算和統計圖像局部區域的梯度方向直方圖來構建特徵，具體細節不在我們涵蓋的範圍裡面，有興趣的同學請參考[補充資料](https://www.cnblogs.com/zyly/p/9651261.html)哦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SZ=20\n",
    "bin_n = 16 # Number of bins\n",
    "\n",
    "def hog(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    gx = cv2.Sobel(img, cv2.CV_32F, 1, 0)\n",
    "    gy = cv2.Sobel(img, cv2.CV_32F, 0, 1)\n",
    "    mag, ang = cv2.cartToPolar(gx, gy)\n",
    "    bins = np.int32(bin_n*ang/(2*np.pi))    # quantizing binvalues in (0...16)\n",
    "    bin_cells = bins[:10,:10], bins[10:,:10], bins[:10,10:], bins[10:,10:]\n",
    "    mag_cells = mag[:10,:10], mag[10:,:10], mag[:10,10:], mag[10:,10:]\n",
    "    hists = [np.bincount(b.ravel(), m.ravel(), bin_n) for b, m in zip(bin_cells, mag_cells)]\n",
    "    hist = np.hstack(hists)     # hist is a 64 bit vector\n",
    "    return hist.astype(np.float32)\n",
    "\n",
    "x_train_hog = np.array([hog(x) for x in x_train])\n",
    "x_test_hog = np.array([hog(x) for x in x_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM model\n",
    "* SVM 是機器學習中一個經典的分類算法，具體細節有興趣可以參考 [該知乎上的解釋](https://www.zhihu.com/question/21094489)，我們這裡直接調用 opencv 中實現好的函數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 用 histogram 特徵訓練 SVM 模型\n",
    "* 訓練過程可能會花點時間，請等他一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_hist = cv2.ml.SVM_create()\n",
    "SVM_hist.setKernel(cv2.ml.SVM_LINEAR)\n",
    "SVM_hist.setGamma(5.383)\n",
    "SVM_hist.setType(cv2.ml.SVM_C_SVC)\n",
    "SVM_hist.setC(2.67)\n",
    "\n",
    "#training\n",
    "SVM_hist.train(x_train_histogram, cv2.ml.ROW_SAMPLE, y_train)\n",
    "\n",
    "# prediction\n",
    "_, y_hist_train = SVM_hist.predict(x_train_histogram)\n",
    "_, y_hist_test = SVM_hist.predict(x_test_histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1448\n",
      "[[383  67 255  60  43  58   6  20  99   9]\n",
      " [174  50 221  61  67 248   3   7 135  34]\n",
      " [189  35 232 116 225 118  16  15  41  13]\n",
      " [198  25 199 103 130 221   7  10  79  28]\n",
      " [ 97  15 237 130 327 127  10  10  40   7]\n",
      " [203  16 230 120 117 194   8   9  92  11]\n",
      " [ 95  24 210 113 292 190  18  25  26   7]\n",
      " [165  30 284 107 167 148   3  12  66  18]\n",
      " [382  18 281  72  34  76   0   3 119  15]\n",
      " [213  50 345  55  47 153   1   2 124  10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.38      0.25      1000\n",
      "           1       0.15      0.05      0.08      1000\n",
      "           2       0.09      0.23      0.13      1000\n",
      "           3       0.11      0.10      0.11      1000\n",
      "           4       0.23      0.33      0.27      1000\n",
      "           5       0.13      0.19      0.15      1000\n",
      "           6       0.25      0.02      0.03      1000\n",
      "           7       0.11      0.01      0.02      1000\n",
      "           8       0.14      0.12      0.13      1000\n",
      "           9       0.07      0.01      0.02      1000\n",
      "\n",
      "   micro avg       0.14      0.14      0.14     10000\n",
      "   macro avg       0.15      0.14      0.12     10000\n",
      "weighted avg       0.15      0.14      0.12     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "print(accuracy_score(y_test, y_hist_test))\n",
    "print(confusion_matrix(y_test, y_hist_test))\n",
    "print(classification_report(y_test, y_hist_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 用 HOG 特徵訓練 SVM 模型\n",
    "* 訓練過程可能會花點時間，請等他一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_hog = cv2.ml.SVM_create()\n",
    "SVM_hog.setKernel(cv2.ml.SVM_LINEAR)\n",
    "SVM_hog.setGamma(5.383)\n",
    "SVM_hog.setType(cv2.ml.SVM_C_SVC)\n",
    "SVM_hog.setC(2.67)\n",
    "\n",
    "#training\n",
    "SVM_hog.train(x_train_hog, cv2.ml.ROW_SAMPLE, y_train)\n",
    "\n",
    "# prediction\n",
    "_, y_hog_train = SVM_hog.predict(x_train_hog)\n",
    "_, y_hog_test = SVM_hog.predict(x_test_hog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1905\n",
      "[[ 62 358  33 183  21  61   5  92  93  92]\n",
      " [ 32 451  44  79  45  34   3  74  43 195]\n",
      " [  9 141  27 392  24 106   5 239  22  35]\n",
      " [  5 149  26 325  34 104  11 294  10  42]\n",
      " [  7 145  19 381  35 100   5 260  22  26]\n",
      " [  2 104   8 327  30 157   4 342   3  23]\n",
      " [  7 155  12 439  18 122  12 177   5  53]\n",
      " [  2 145  19 205  29  85   6 449   8  52]\n",
      " [ 46 387  36 111  26  27   0  75 165 127]\n",
      " [ 16 333  49  96  32  19   6 195  32 222]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.06      0.10      1000\n",
      "           1       0.19      0.45      0.27      1000\n",
      "           2       0.10      0.03      0.04      1000\n",
      "           3       0.13      0.33      0.18      1000\n",
      "           4       0.12      0.04      0.05      1000\n",
      "           5       0.19      0.16      0.17      1000\n",
      "           6       0.21      0.01      0.02      1000\n",
      "           7       0.20      0.45      0.28      1000\n",
      "           8       0.41      0.17      0.24      1000\n",
      "           9       0.26      0.22      0.24      1000\n",
      "\n",
      "   micro avg       0.19      0.19      0.19     10000\n",
      "   macro avg       0.21      0.19      0.16     10000\n",
      "weighted avg       0.21      0.19      0.16     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "print(accuracy_score(y_test, y_hog_test))\n",
    "print(confusion_matrix(y_test, y_hog_test))\n",
    "print(classification_report(y_test, y_hog_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
